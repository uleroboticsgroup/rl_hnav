<mxfile host="app.diagrams.net" agent="Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36" version="29.3.4" pages="2">
  <diagram id="arch" name="G1 Unified Architecture (ROS 2 Humble)">
    <mxGraphModel dx="1994" dy="1106" grid="1" gridSize="10" guides="1" tooltips="1" connect="1" arrows="1" fold="1" page="1" pageScale="1" pageWidth="1169" pageHeight="827" math="0" shadow="0">
      <root>
        <mxCell id="0" />
        <mxCell id="1" parent="0" />
        <mxCell id="t1" parent="1" style="rounded=1;whiteSpace=wrap;html=1;fillColor=#1E5A8C;fontColor=#FFFFFF;strokeColor=#1E5A8C;align=center;verticalAlign=middle;fontSize=18;fontStyle=1;" value="Vision–Language–Reasoning Architecture for a Trustworthy Humanoid Waiter (Unitree G1) — ROS 2 Humble" vertex="1">
          <mxGeometry height="60" width="1080" x="40" as="geometry" />
        </mxCell>
        <mxCell id="h1" parent="1" style="rounded=1;whiteSpace=wrap;html=1;fillColor=#E9F2FA;strokeColor=#1E5A8C;fontSize=14;fontStyle=1;" value="Human Interaction&lt;br&gt;(Speech / Text / Service Command)&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;div&gt;&lt;font style=&quot;font-size: 14px;&quot;&gt;The interaction begins with a human-issued service command,&lt;span style=&quot;font-weight: normal;&quot;&gt; expressed through speech or text (e.g., &lt;/span&gt;&lt;em data-start=&quot;742&quot; data-end=&quot;774&quot; style=&quot;&quot;&gt;“Serve the clients at table X”&lt;/em&gt;&lt;span style=&quot;font-weight: normal;&quot;&gt;).&amp;nbsp;&lt;/span&gt;&lt;/font&gt;&lt;/div&gt;&lt;/div&gt;" vertex="1">
          <mxGeometry height="100" width="1210" x="390" y="110" as="geometry" />
        </mxCell>
        <mxCell id="p0" parent="1" style="rounded=1;whiteSpace=wrap;html=1;fillColor=#F5F5F5;strokeColor=#B0B0B0;fontSize=13;" value="&lt;font style=&quot;font-size: 18px;&quot;&gt;Perception (ROS 2 sensors)&lt;br&gt;• RGB/Depth camera&lt;br&gt;• Microphone&lt;br&gt;• IMU / Odometry&lt;/font&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;In parallel, &lt;b&gt;the robot continuously perceives its environment through onboard sensors&lt;/b&gt;, including RGB–D cameras and proprioceptive feedback (IMU, odometry). &lt;b&gt;A computer vision module detects objects, people, and obstacles, producing a set of perceptual candidates that describe the current scene&lt;/b&gt;.&lt;/div&gt;" vertex="1">
          <mxGeometry height="230" width="310" x="20" y="299" as="geometry" />
        </mxCell>
        <mxCell id="kg" parent="1" style="rounded=1;whiteSpace=wrap;html=1;fillColor=#FFFFFF;strokeColor=#666666;fontSize=13;fontStyle=1;" value="Knowledge / Context&#xa;(tables, zones, policies)&#xa;Optional: Knowledge Graph" vertex="1">
          <mxGeometry height="110" width="250" x="1680" y="359" as="geometry" />
        </mxCell>
        <mxCell id="VZcMFcZDBxtN5G_U3fJv-4" edge="1" parent="1" source="m1" style="edgeStyle=orthogonalEdgeStyle;rounded=0;orthogonalLoop=1;jettySize=auto;html=1;strokeWidth=2;" target="g1" value="">
          <mxGeometry relative="1" as="geometry" />
        </mxCell>
        <mxCell id="m1" parent="1" style="rounded=1;whiteSpace=wrap;html=1;fillColor=#EEF2FF;strokeColor=#3B5BA9;fontSize=13;fontStyle=1;" value="&lt;div style=&quot;&quot;&gt;&lt;span style=&quot;background-color: transparent; color: light-dark(rgb(0, 0, 0), rgb(255, 255, 255));&quot;&gt;Mission &amp;amp; Reasoning Layer (llm_node)&lt;/span&gt;&lt;/div&gt;&lt;div style=&quot;&quot;&gt;&lt;span style=&quot;background-color: transparent; color: light-dark(rgb(0, 0, 0), rgb(255, 255, 255));&quot;&gt;• Interpret service intent (serve/clear/order)&lt;/span&gt;&lt;/div&gt;&lt;div style=&quot;&quot;&gt;&lt;span style=&quot;background-color: transparent; color: light-dark(rgb(0, 0, 0), rgb(255, 255, 255));&quot;&gt;• Detect ambiguity &amp;amp; uncertainty&lt;/span&gt;&lt;/div&gt;&lt;div style=&quot;&quot;&gt;&lt;span style=&quot;background-color: transparent; color: light-dark(rgb(0, 0, 0), rgb(255, 255, 255));&quot;&gt;• Ask clarification/confirmation&lt;/span&gt;&lt;/div&gt;&lt;div style=&quot;&quot;&gt;&lt;span style=&quot;background-color: transparent; color: light-dark(rgb(0, 0, 0), rgb(255, 255, 255));&quot;&gt;• Explain decisions&lt;/span&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;span style=&quot;background-color: transparent; color: light-dark(rgb(0, 0, 0), rgb(255, 255, 255)); text-align: center; caret-color: rgba(0, 0, 0, 0); font-size: 14px; font-weight: normal;&quot;&gt;These commands are treated&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;background-color: transparent; color: light-dark(rgb(0, 0, 0), rgb(255, 255, 255)); text-align: center; caret-color: rgba(0, 0, 0, 0); font-size: 14px;&quot;&gt;as high-level intents&lt;/span&gt;&lt;span style=&quot;background-color: transparent; color: light-dark(rgb(0, 0, 0), rgb(255, 255, 255)); text-align: center; caret-color: rgba(0, 0, 0, 0); font-size: 14px; font-weight: normal;&quot;&gt;&amp;nbsp;rather than explicit instructions, acknowledging the inherent ambiguity of natural language in real-world service settings.&amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;background-color: transparent; color: light-dark(rgb(0, 0, 0), rgb(255, 255, 255)); caret-color: rgba(0, 0, 0, 0); font-weight: normal;&quot;&gt;To align perception with language,&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;background-color: transparent; color: light-dark(rgb(0, 0, 0), rgb(255, 255, 255)); caret-color: rgba(0, 0, 0, 0);&quot;&gt;a&amp;nbsp;&lt;/span&gt;&lt;span data-start=&quot;1284&quot; data-end=&quot;1315&quot; style=&quot;background-color: transparent; color: light-dark(rgb(0, 0, 0), rgb(255, 255, 255)); caret-color: rgba(0, 0, 0, 0);&quot;&gt;Vision–Language Model (VLM)&lt;/span&gt;&lt;span style=&quot;background-color: transparent; color: light-dark(rgb(0, 0, 0), rgb(255, 255, 255)); caret-color: rgba(0, 0, 0, 0);&quot;&gt;&amp;nbsp;performs grounding between the user request and the detected candidates&lt;/span&gt;&lt;span style=&quot;background-color: transparent; color: light-dark(rgb(0, 0, 0), rgb(255, 255, 255)); caret-color: rgba(0, 0, 0, 0); font-weight: normal;&quot;&gt;. This module ranks objects or locations according to&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;background-color: transparent; color: light-dark(rgb(0, 0, 0), rgb(255, 255, 255)); caret-color: rgba(0, 0, 0, 0);&quot;&gt;their semantic relevance&lt;/span&gt;&lt;span style=&quot;background-color: transparent; color: light-dark(rgb(0, 0, 0), rgb(255, 255, 255)); caret-color: rgba(0, 0, 0, 0); font-weight: normal;&quot;&gt;&amp;nbsp;(e.g., identifying which drink best matches&amp;nbsp;&lt;/span&gt;&lt;em data-start=&quot;1510&quot; data-end=&quot;1539&quot; style=&quot;background-color: transparent; color: light-dark(rgb(0, 0, 0), rgb(255, 255, 255)); caret-color: rgba(0, 0, 0, 0); font-weight: normal;&quot;&gt;“the drink near the window”&lt;/em&gt;&lt;span style=&quot;background-color: transparent; color: light-dark(rgb(0, 0, 0), rgb(255, 255, 255)); caret-color: rgba(0, 0, 0, 0); font-weight: normal;&quot;&gt;),&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;background-color: transparent; color: light-dark(rgb(0, 0, 0), rgb(255, 255, 255)); caret-color: rgba(0, 0, 0, 0);&quot;&gt;transforming raw detections into semantically meaningful hypotheses&lt;/span&gt;&lt;span style=&quot;background-color: transparent; color: light-dark(rgb(0, 0, 0), rgb(255, 255, 255)); caret-color: rgba(0, 0, 0, 0); font-weight: normal;&quot;&gt;.&lt;/span&gt;&lt;/div&gt;" vertex="1">
          <mxGeometry height="150" width="1210" x="390" y="264" as="geometry" />
        </mxCell>
        <mxCell id="g1" parent="1" style="rounded=1;whiteSpace=wrap;html=1;fillColor=#F3E8FF;strokeColor=#7B4BB3;fontSize=13;fontStyle=1;strokeWidth=3;" value="Planning &amp;amp; Grounding Layer (vlm_node + planner)&lt;br&gt;• Detect objects/people/obstacles (CV/YOLO)&lt;br&gt;• VLM grounding: rank candidates for the query&lt;br&gt;• Decompose task into sub-goals (approach, confirm, pick/place)&lt;br&gt;• Context reasoning (tables, customers, safe distances)&lt;div&gt;&lt;span style=&quot;background-color: transparent; color: light-dark(rgb(0, 0, 0), rgb(255, 255, 255));&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;font style=&quot;font-size: 14px;&quot;&gt;&lt;span style=&quot;font-weight: normal; background-color: transparent; color: light-dark(rgb(0, 0, 0), rgb(255, 255, 255));&quot;&gt;At the core of the architecture lies a &lt;/span&gt;&lt;span data-start=&quot;1651&quot; data-end=&quot;1681&quot; style=&quot;background-color: transparent; color: light-dark(rgb(0, 0, 0), rgb(255, 255, 255));&quot;&gt;Large Language Model (LLM)&lt;/span&gt;&lt;span style=&quot;background-color: transparent; color: light-dark(rgb(0, 0, 0), rgb(255, 255, 255));&quot;&gt;, which serves as the deliberative reasoning component&lt;span style=&quot;font-weight: normal;&quot;&gt;. The LLM integrates the user request, VLM-ranked candidates, and optional contextual knowledge (e.g., table layout or service rules). It interprets the task intent, detects ambiguity, and determines whether execution can proceed safely or whether clarification or confirmation is required. Crucially, the LLM also generates human-understandable explanations of its decisions, enabling transparent interaction.&lt;/span&gt;&lt;/span&gt;&lt;/font&gt;&lt;/div&gt;" vertex="1">
          <mxGeometry height="160" width="1210" x="390" y="440" as="geometry" />
        </mxCell>
        <mxCell id="e1" parent="1" style="rounded=1;whiteSpace=wrap;html=1;fillColor=#FFF7ED;strokeColor=#C26A1B;fontSize=13;fontStyle=1;" value="&lt;div&gt;&lt;br&gt;&lt;/div&gt;Executive Layer (nav_exec_node + unitree_control_node)&lt;br&gt;• Social goal generation (table/target pose)&lt;br&gt;• Socially-aware navigation &amp;amp; obstacle avoidance (Nav2 + human-aware rules)&lt;br&gt;• Gait control / balance / manipulation interfaces&lt;br&gt;• Runtime monitoring &amp;amp; safe stop&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;font style=&quot;font-size: 14px;&quot;&gt;&lt;span style=&quot;font-weight: normal;&quot;&gt;Once the task is validated, a planning module decomposes &lt;/span&gt;the high-level intent into executable sub-goals, such as navigating to a target table, positioning safely relative to customers&lt;span style=&quot;font-weight: normal;&quot;&gt;, and performing service actions.&amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;font-weight: normal; background-color: transparent; color: light-dark(rgb(0, 0, 0), rgb(255, 255, 255));&quot;&gt;Execution is handled by a &lt;/span&gt;&lt;span style=&quot;background-color: transparent; color: light-dark(rgb(0, 0, 0), rgb(255, 255, 255));&quot;&gt;Nav2-based navigation executor&lt;/span&gt;&lt;span style=&quot;font-weight: normal; background-color: transparent; color: light-dark(rgb(0, 0, 0), rgb(255, 255, 255));&quot;&gt; integrated with the Unitree G1 control stack.&amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;font-weight: normal; background-color: transparent; color: light-dark(rgb(0, 0, 0), rgb(255, 255, 255));&quot;&gt;Throughout execution, a dialogue interface enables the robot to &lt;/span&gt;&lt;span style=&quot;background-color: transparent; color: light-dark(rgb(0, 0, 0), rgb(255, 255, 255));&quot;&gt;communicate its intentions, request confirmations&lt;/span&gt;&lt;span style=&quot;font-weight: normal; background-color: transparent; color: light-dark(rgb(0, 0, 0), rgb(255, 255, 255));&quot;&gt; (e.g., &lt;/span&gt;&lt;em data-start=&quot;2985&quot; data-end=&quot;3017&quot; style=&quot;font-weight: normal; background-color: transparent; color: light-dark(rgb(0, 0, 0), rgb(255, 255, 255));&quot;&gt;“Have you finished your meal?”&lt;/em&gt;&lt;span style=&quot;font-weight: normal; background-color: transparent; color: light-dark(rgb(0, 0, 0), rgb(255, 255, 255));&quot;&gt;), and &lt;/span&gt;&lt;span style=&quot;background-color: transparent; color: light-dark(rgb(0, 0, 0), rgb(255, 255, 255));&quot;&gt;report task completion&lt;/span&gt;&lt;span style=&quot;font-weight: normal; background-color: transparent; color: light-dark(rgb(0, 0, 0), rgb(255, 255, 255));&quot;&gt;.&lt;/span&gt;&lt;/font&gt;&lt;br&gt;&lt;/div&gt;" vertex="1">
          <mxGeometry height="165" width="1220" x="390" y="630" as="geometry" />
        </mxCell>
        <mxCell id="a1" parent="1" style="rounded=1;whiteSpace=wrap;html=1;fillColor=#FFFFFF;strokeColor=#333333;fontSize=13;fontStyle=1;" value="Unitree G1 Actions&#xa;• Navigate to target&#xa;• Speak / confirm&#xa;• Manipulate / serve / clear" vertex="1">
          <mxGeometry height="140" width="310" x="20" y="655" as="geometry" />
        </mxCell>
        <mxCell id="f1" parent="1" style="rounded=1;whiteSpace=wrap;html=1;fillColor=#E8FFF2;strokeColor=#2F9E5B;fontSize=13;fontStyle=1;" value="Feedback Loop (runtime)&#xa;• Perception updates during motion&#xa;• Re-rank targets if scene changes&#xa;• Explain / re-confirm when needed" vertex="1">
          <mxGeometry height="80" width="220" x="1695" y="230" as="geometry" />
        </mxCell>
        <mxCell id="ar1" edge="1" parent="1" source="h1" style="endArrow=block;html=1;strokeWidth=2;strokeColor=#444444;" target="m1">
          <mxGeometry relative="1" as="geometry" />
        </mxCell>
        <mxCell id="ar2" edge="1" parent="1" source="p0" style="endArrow=block;html=1;strokeWidth=2;strokeColor=#444444;entryX=0;entryY=0.5;entryDx=0;entryDy=0;exitX=1;exitY=0.5;exitDx=0;exitDy=0;" target="m1">
          <mxGeometry relative="1" as="geometry">
            <Array as="points">
              <mxPoint x="360" y="414" />
              <mxPoint x="360" y="340" />
            </Array>
          </mxGeometry>
        </mxCell>
        <mxCell id="ar4" edge="1" parent="1" source="g1" style="endArrow=block;html=1;strokeWidth=2;strokeColor=#444444;" target="e1">
          <mxGeometry relative="1" as="geometry" />
        </mxCell>
        <mxCell id="ar5" edge="1" parent="1" source="e1" style="endArrow=block;html=1;strokeWidth=2;strokeColor=#444444;" target="a1">
          <mxGeometry relative="1" as="geometry" />
        </mxCell>
        <mxCell id="ar6" edge="1" parent="1" source="a1" style="endArrow=block;html=1;strokeWidth=2;strokeColor=#2F9E5B;" target="p0">
          <mxGeometry relative="1" as="geometry" />
        </mxCell>
        <mxCell id="ar9" edge="1" parent="1" source="m1" style="endArrow=block;html=1;strokeWidth=2;strokeColor=#2F9E5B;dashed=1;exitX=1;exitY=0.25;exitDx=0;exitDy=0;entryX=0;entryY=0.5;entryDx=0;entryDy=0;" target="f1">
          <mxGeometry relative="1" as="geometry" />
        </mxCell>
        <mxCell id="-yqbikXj7jkKl2m_y0p9-3" edge="1" parent="1" style="endArrow=none;dashed=1;html=1;dashPattern=1 3;strokeWidth=3;rounded=0;" value="">
          <mxGeometry height="50" relative="1" width="50" as="geometry">
            <Array as="points">
              <mxPoint x="1660" y="827" />
              <mxPoint x="370" y="827" />
              <mxPoint x="370" y="232" />
            </Array>
            <mxPoint x="1660" y="242" as="sourcePoint" />
            <mxPoint x="1660" y="242" as="targetPoint" />
          </mxGeometry>
        </mxCell>
        <mxCell id="-yqbikXj7jkKl2m_y0p9-5" parent="1" style="shape=actor;whiteSpace=wrap;html=1;" value="" vertex="1">
          <mxGeometry height="60" width="40" x="830" y="120" as="geometry" />
        </mxCell>
        <mxCell id="VZcMFcZDBxtN5G_U3fJv-1" parent="1" style="rounded=1;whiteSpace=wrap;html=1;" value="The proposed system implements a &lt;strong data-start=&quot;254&quot; data-end=&quot;296&quot;&gt;Vision–Language–Reasoning architecture&lt;/strong&gt; for a humanoid waiter operating in dynamic restaurant environments. Designed for deployment on the &lt;strong data-start=&quot;396&quot; data-end=&quot;425&quot;&gt;Unitree G1 humanoid robot&lt;/strong&gt; under &lt;strong data-start=&quot;432&quot; data-end=&quot;448&quot;&gt;ROS 2 Humble&lt;/strong&gt;, the architecture bridges high-level human intent with low-level robot execution to enable &lt;strong data-start=&quot;540&quot; data-end=&quot;567&quot;&gt;transparent interaction&lt;/strong&gt;, &lt;strong data-start=&quot;569&quot; data-end=&quot;604&quot;&gt;ambiguity-aware decision making&lt;/strong&gt;, and &lt;strong data-start=&quot;610&quot; data-end=&quot;639&quot;&gt;socially-aware navigation&lt;/strong&gt;." vertex="1">
          <mxGeometry height="150" width="320" x="40" y="110" as="geometry" />
        </mxCell>
        <mxCell id="VZcMFcZDBxtN5G_U3fJv-11" edge="1" parent="1" source="kg" style="edgeStyle=elbowEdgeStyle;elbow=horizontal;html=1;rounded=1;curved=0;sourcePerimeterSpacing=0;targetPerimeterSpacing=0;startSize=6;endSize=6;exitX=0;exitY=0.5;exitDx=0;exitDy=0;dashed=1;strokeWidth=2;entryX=1;entryY=0.5;entryDx=0;entryDy=0;" target="m1" value="">
          <mxGeometry relative="1" as="geometry">
            <mxPoint x="1720" y="445" as="sourcePoint" />
            <mxPoint x="1630" y="340" as="targetPoint" />
          </mxGeometry>
        </mxCell>
        <mxCell id="VZcMFcZDBxtN5G_U3fJv-13" connectable="0" parent="VZcMFcZDBxtN5G_U3fJv-11" style="edgeLabel;html=1;align=center;verticalAlign=middle;resizable=0;points=[];" value="Text" vertex="1">
          <mxGeometry relative="1" x="-0.1459" y="2" as="geometry">
            <mxPoint as="offset" />
          </mxGeometry>
        </mxCell>
        <mxCell id="VZcMFcZDBxtN5G_U3fJv-12" edge="1" parent="1" source="kg" style="edgeStyle=elbowEdgeStyle;elbow=horizontal;html=1;rounded=1;curved=0;sourcePerimeterSpacing=0;targetPerimeterSpacing=0;startSize=6;endSize=6;entryX=1;entryY=0.5;entryDx=0;entryDy=0;exitX=0;exitY=0.5;exitDx=0;exitDy=0;dashed=1;strokeWidth=2;" target="g1" value="">
          <mxGeometry relative="1" as="geometry">
            <mxPoint x="1710" y="414" as="sourcePoint" />
            <mxPoint x="1620" y="494" as="targetPoint" />
          </mxGeometry>
        </mxCell>
      </root>
    </mxGraphModel>
  </diagram>
  <diagram id="modes" name="Modes A / B / C (Operational)">
    <mxGraphModel dx="1200" dy="800" grid="1" gridSize="10" guides="1" tooltips="1" connect="1" arrows="1" fold="1" page="1" pageScale="1" pageWidth="1169" pageHeight="827" math="0" shadow="0">
      <root>
        <mxCell id="0" />
        <mxCell id="1" parent="0" />
        <mxCell id="mt" value="Operational Interaction Modes for a Humanoid Waiter (Unitree G1) — ROS 2 Humble" style="rounded=1;whiteSpace=wrap;html=1;fillColor=#1E5A8C;fontColor=#FFFFFF;strokeColor=#1E5A8C;align=center;verticalAlign=middle;fontSize=18;fontStyle=1;" vertex="1" parent="1">
          <mxGeometry x="40" y="20" width="1080" height="60" as="geometry" />
        </mxCell>
        <!-- Mode A -->
        <mxCell id="ma" value="Mode A — Reactive (Vision-only)&#xa;Input: user command + detections&#xa;Decision: heuristics (nearest / spatial rules)&#xa;Behavior: acts immediately&#xa;Limits: silent failures under ambiguity; low transparency" style="rounded=1;whiteSpace=wrap;html=1;fillColor=#FFF7ED;strokeColor=#C26A1B;fontSize=14;fontStyle=1;" vertex="1" parent="1">
          <mxGeometry x="60" y="140" width="330" height="220" as="geometry" />
        </mxCell>
        <!-- Mode B -->
        <mxCell id="mb" value="Mode B — Grounded (Vision + VLM)&#xa;Input: user command + scene candidates&#xa;Decision: VLM grounding ranks candidates&#xa;Behavior: selects top candidate and executes&#xa;Limits: still opaque; weak uncertainty handling" style="rounded=1;whiteSpace=wrap;html=1;fillColor=#F3E8FF;strokeColor=#7B4BB3;fontSize=14;fontStyle=1;" vertex="1" parent="1">
          <mxGeometry x="420" y="140" width="330" height="220" as="geometry" />
        </mxCell>
        <!-- Mode C -->
        <mxCell id="mc" value="Mode C — Socially Reliable (Vision + VLM + LLM)&#xa;Input: user command + perception + context&#xa;Decision: LLM reasons over VLM candidates + uncertainty&#xa;Behavior: explains, asks clarification/confirmation, adapts during motion&#xa;Benefits: fewer silent errors; higher trust; socially-aware navigation" style="rounded=1;whiteSpace=wrap;html=1;fillColor=#E8FFF2;strokeColor=#2F9E5B;fontSize=14;fontStyle=1;" vertex="1" parent="1">
          <mxGeometry x="780" y="140" width="340" height="220" as="geometry" />
        </mxCell>
        <!-- Shared Examples -->
        <mxCell id="ex" value="Example service messages (high-level goals)&#xa;• “Serve the clients at table X”&#xa;• “Clear table Y” → confirm: “Have you finished?”&#xa;• “Take orders from table Z”&#xa;&#xa;Mode C adds: explain-before-act + safe navigation + human-aware obstacle avoidance" style="rounded=1;whiteSpace=wrap;html=1;fillColor=#E9F2FA;strokeColor=#1E5A8C;fontSize=14;fontStyle=1;" vertex="1" parent="1">
          <mxGeometry x="60" y="400" width="1060" height="160" as="geometry" />
        </mxCell>
        <!-- Arrows -->
        <mxCell id="arrA" style="endArrow=block;html=1;strokeWidth=2;strokeColor=#777777;" edge="1" parent="1" source="ma" target="mb">
          <mxGeometry relative="1" as="geometry" />
        </mxCell>
        <mxCell id="arrB" style="endArrow=block;html=1;strokeWidth=2;strokeColor=#777777;" edge="1" parent="1" source="mb" target="mc">
          <mxGeometry relative="1" as="geometry" />
        </mxCell>
      </root>
    </mxGraphModel>
  </diagram>
</mxfile>
